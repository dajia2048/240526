---
title: 'OpenAI为什么总是领先一个版本'
categories: ['36krai']
date: Sun, 18 Feb 2024 12:02:12 GMT
lastmod: Sun, 18 Feb 2024 12:02:12 GMT
author: ["g0f"]
tags:
- read
draft: false 
comments: true
reward: true 
mermaid: true 
showToc: true 
TocOpen: true 
hidemeta: false 
disableShare: true 
showbreadcrumbs: true 
cover:
    image: "/hugo-logo-wide.svg"
    alt: 果粉圈
    relative: false
---

<div>

<div> Sora视频模型, OpenAI, AI界, 技术积累, 人工智能
Sora视频模型发布引起轰动，展现出其能够创建高度详细、充满情感的视频。业界对其评价褒贬不一，有人认为颠覆性巨大，有人则认为略显一般。OpenAI选择以立体建模为理念区别，通过对视频生成模型的技术积累和经验，构建了Sora模型。技术层面的创新表现在使用Patch替代token进行计算，并借鉴GPT模型在进行视频训练时添加文字说明等方式，提高了整体视频质量。这种技术领先的优势可能成为一种惯性，难以被其他公司追赶。AI时代的有效增量是设计AI或者超越AI创意的设计。总之，OpenAI的Sora模型在技术上展现了领先，但也提高了创新的门槛。 <br/><br/>总结: Sora视频模型的发布在AI界引起轰动，展现了其能够创建高度详细、充满情感的视频。OpenAI选择以立体建模为理念区别，并利用技术积累和经验构建了Sora模型。技术创新体现在使用Patch替代token进行计算，并借鉴GPT模型的方式提高了整体视频质量。这种领先状态可能成为一种惯性，AI时代的有效增量是设计AI或者超越AI创意的设计。 Sora模型在技术上展现了领先，但也提高了创新的门槛。 <div>
<p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_7c562287fc7146969c19a46dd4c139d7@46958_oswg163044oswg742oswg489_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1"/></p><p>Sora视频模型的发布，几乎复刻了一年半之前GPT-3初登场时的AI圈盛况： </p><p><strong>突然出现，引起热议，广为震惊。</strong></p><p>北京时间2月16日，在没有任何消息外泄、事先预告的情况下，OpenAI在社交平台X（原推特）发帖，首次对外公布了名为Sora的文生视频AI模型。 </p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a6168d0b22ae4a72a4bddfbccc6bf79f@46958_oswg835031oswg917oswg1209_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1"/></p><p>一句“Introducing Sora, our text-to-video model（介绍一下Sora，我们的文本转视频模型）”，切入正题之简短，比起宣发，更像是一则告知：<strong>是的，我们又掏出大的来了。</strong></p><p>之后，便是对Sora模型的能力介绍：Sora可以创建长达60秒的视频，其中包含高度详细的场景、复杂的摄像机运动以及充满活力、情感的多个角色。 </p><p>还附上了演示案例的对应Prompt（提示词）：美丽、白雪皑皑的东京城很繁华。镜头穿过熙熙攘攘的城市街道，跟随几个人享受美丽的雪天并在附近的摊位购物。美丽的樱花花瓣随着雪花在风中飞舞。 </p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_a2de27cfeb0344e988ec5b93bf3f4ecd@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1"/></p><p>对于Sora，业界评价并不统一： </p><p><strong>有人100%认可，也有人120%、200%认可。</strong></p><p>360创始人周鸿祎发文称，Sora意味着实现通用人工智能可能从10年缩短至1年，该模型展现的不仅是视频制作的能力，还展现了大模型对真实世界有了理解和模拟之后，会带来新的成果和突破。 </p><p>英伟达人工智能研究院首席研究科学家Jim Fan将Sora称作是视频生成领域的GPT-3时刻：Sora是一个“数据驱动的物理引擎”，一个可学习的模拟器或“世界模型”。 </p><p>高强度网上冲浪且一向心直口快的马斯克则直接打出gg human（人类输了） 。 </p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_859269d1c10a4fb5b50ce4bc8287a88d@46958_oswg759628oswg905oswg1092_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1"/></p><p>暂且不去深究后续影响到底是积极还是消极，能给AI、影视、社媒等一众行业同步带来颠覆性王炸、划时代之感的，又是OpenAI，总是OpenAI。 </p><p>像是一群工程师还在讨论如何进一步完善登月计划，OpenAI的团队已经从火星传回来一组自拍——他们总是领先一个版本，为什么？ </p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_3b448392ef5b40aabcdae16838fd6f93@46958_oswg797239oswg923oswg1135_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1"/></p><p>前文英伟达AI研究院科学家Jim Fan对于Sora的评价，从技术层面来看很有参考性：他将Sora定义为物理引擎和世界模型。传统意义上的视频画面是二维，而人们身处的物理世界是三维的。 </p><p>这成为了AI视频模型设计之初的理念区别：在生成视频的过程中，AI的作用到底应该是将多段视频片段拆分组合，还是应该作为一个主体，构建并记录一个虚拟的AI空间。 </p><p>OpenAI的选择是后者。 </p><p>其官网发布的Sora技术报告中，有一句话值得注意：“我们的结果表明，发展能够模拟物理世界动态的通用模拟器是一条充满希望的途径，具有前所未有的准确度和现实感。” </p><p>做一个粗浅的理解就是，Sora不是编辑视频，而是在生成视频之前先建模一个空间，然后变成一个镜头记录这个三维立体的虚拟空间。 </p><p>立体建模能展现信息量远远多于平面图，<strong>从设计思路上OpenAI就领先了一个维度，或者说提前了一个版本。</strong></p><p>当然，更多的信息量意味着更庞大的数据流，在有限算力内跑出更好效果、在保证效果的前提下尽量节约算力，本质上是同一个问题：AI计算效率。 </p><p>但对于OpenAI来说，这些问题都有经验可循——<strong>从ChatGPT到GPT-4等等项目的技术积累，成为OpenAI构建Sora模型的良好地基。</strong></p><p>受大语言模型成功案例启发，OpenAI在探索视频模型时就在思考“如何获得类似的好处”：大模型运转期间，token（词汇单元）作为自然语言处理任务中的最小文本单位，承载着输入信息的作用，帮助模型对文本进行处理和理解。ChatGPT将代码、数学以及各种不同的自然语言一并拆分为token，再交由模型对token进行处理和理解，并能够通过学习token之间的关系来获取更多的语义信息。 </p><p>同理，在视频生成模型中，OpenAI也创造了与token对应的数据单位“Patch”（图像单元），将图形语言转化为对应格式的Patch进行计算，在保证模型扩展性的同时，大幅提升单位算力内的运算效率。 </p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_38265689e8e345c68f4d3db82b141c04@46958_oswg213146oswg1080oswg201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1"/></p><p>而在模型的前端，OpenAI同样用上了自己在GPT系列模型的成果： </p><p>和文本对话类似，训练文生视频的过程中，除了需要视频素材案例之外，同样需要大量对应的文字说明。OpenAI采用了最初在DALL·E 3中提出的“重新加标题”模式，用具备高度描述性的标题生成器为训练集中的视频素材生成文字说明。生成结果也证明了，在制作期间为素材添加额外的说明，可以提高包括准确性在内的整体视频质量。 </p><p>此外，仿照DALL·E 3的做法，OpenAI还另外使用GPT对用户输入的简短提示词进行了更便于AI理解的扩写，把用户输入的文字扩充成更长、更详尽的说明，再交由视频生成模型进行处理。 </p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240218/v2_358996e42ee6428082fad6003e154d5b@46958_oswg393563oswg1080oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1"/></p><p>对于OpenAI这类技术驱动型公司来说，经验和技术的积累都是加速度，有迹可循的成功经验叠加团队自身对AI概念领先理解，让OpenAI总是能踩在自己的肩膀向上，或是推着自己加速向前。 </p><p>比技术领先更可怕或者说更值得友商在意的，是这种领先往往会成为惯性，一步快步步快。指望靠加速追赶和对标与OpenAI看齐，在配套设施愈发成熟的阶段，难度恐怕只会不降反增。真正的增量，仍在顶层设计的创新之中。 </p><p>所以，与其说是AI挤占了人的创新空间，倒不如说是AI拉高了有效创新的门槛：设计AI，或者能超越AI创意的设计，才是大模型时代的有效增量。 </p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/3tW9UTKVWp2m1kYiGXcyfg" rel="noopener noreferrer nofollow" target="_blank">“AI蓝媒汇”（ID:lanmeih001）</a>，作者：陶然，36氪经授权发布。</p>
</div></div>
</div>

<div>
[原文](https://www.36kr.com/p/2653966202764416)
</div>

