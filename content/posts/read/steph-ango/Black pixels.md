---
title: 'Black pixels'
categories: ['steph-ango']
keywords: ['steph-ango']
date: None
lastmod: None
author: [['steph-ango']]
tags: ['steph-ango']
draft: false 
comments: true
reward: true 
mermaid: true 
showToc: true 
TocOpen: true 
hidemeta: false 
disableShare: true 
showbreadcrumbs: true 
cover:
    image: cdn.g0f.cn/?r=https://stephanango.com&url=https://kepano.s3.amazonaws.com/prometheus-ui.jpg
    alt: "Black pixels"
    relative: false
---

<div>

<p>One of my first industrial design jobs was working on a headset that never shipped, for a now defunct startup. It used two micro-OLED displays similar to the ones in Apple’s Vision Pro, but with clear, see-through optics reflected into the eye through a kind of one-way mirror lenses (<a href="https://en.wikipedia.org/wiki/Beam_splitter" target="_blank">beam-splitters</a>).</p>
<p>In retrospect, it was crazy to think that a small independent startup could bring together all the necessary technology to make this happen.</p>
<p>One thing we got wrong is that we believed in the superiority of a see-through optical system. At the time, around 2011, this seemed like a much better approach, because there was no latency or distortion when looking at the real world. But since then I became convinced that a pass-through display is the best near-term solution.</p>
<p>The reason is simple. You need black pixels.</p>
<p>What Apple showed this week is that we now have the technology to make the camera-to-display pipeline imperceptibly responsive and high-resolution.</p>
<p>If you have ever watched a sci-fi movie with HUDs or holographic interfaces you’ll notice that the backgrounds of the environments are always dark. That’s because these displays can only project light, on a spectrum from transparent to white.</p>
<figure class="wide">
<img alt="Scene from Prometheus" src="cdn.g0f.cn/?r=https://stephanango.com&url=https://kepano.s3.amazonaws.com/prometheus-ui.jpg"/>
<figcaption>Holographic interface from <em>Prometheus</em> (2012)</figcaption>
</figure>
<p>While this looks very cool, it is quite impractical in every day use, and significantly reduces the usefulness of the device. For all practical purposes any device that works with a see-through optics is going to have this limitation.</p>
<p>Apple’s Vision Pro demos highlight three key things you just can’t do without black pixels:</p>
<ol>
<li>Black text and black backgrounds</li>
<li>Virtual shadows</li>
<li>Environmental dimming</li>
</ol>
<p>If you want to be able to have any kind of true black text in a mixed reality setting, you need to be able to control the rendering of the image from the ground up.</p>
<p>Apple encourages digital elements to cast virtual shadows on real world objects, and provides the necessary tools to do so easily.</p>
<figure class="wide">
<img alt="Example of a digital element casting a dark shadow" src="cdn.g0f.cn/?r=https://stephanango.com&url=https://kepano.s3.amazonaws.com/vision-pro-hello.jpeg"/>
<figcaption>This still from Apple shows a digital element casting a digital shadow on a real world table</figcaption>
</figure>
<p>Apple also shows how you can dim the entire environment to a darker color, to bring digital elements to the forefront. In the example below you can even see an album cover with a completely black background.</p>
<figure class="wide">
<img alt="Example showing the environment being darkened digitally" src="cdn.g0f.cn/?r=https://stephanango.com&url=https://kepano.s3.amazonaws.com/vision-pro-dimming.jpeg"/>
<figcaption>This still from Apple shows the environment being darkened digitally</figcaption>
</figure>
<p>The end result feels much more natural, immersive, and opens up more applications.</p>

</div>

<div>
[原文](https://stephanango.com/black-pixels)
</div>

